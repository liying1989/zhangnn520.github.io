# 📃 Surveys

### A Survey of Large Language Models

* Renmin University of China
* [https://arxiv.org/pdf/2303.18223.pdf](https://arxiv.org/pdf/2303.18223.pdf)
* 通过介绍背景、主要发现和主流技术来回顾LLMs的最新进展。重点关注LLM的四个主要方面，即预训练、适应调优、利用和能力评估。此外，总结了发展LLMs的可用资源，并讨论了未来方向的剩余问题。

### Augmented Language Models: a Survey

* Meta AI
* [https://arxiv.org/abs/2302.07842](https://arxiv.org/abs/2302.07842)
* 回顾了通过推理技能和使用工具的能力增强语言模型 (LM) 的工作

### Large Language Models Meet NL2Code: A Survey (2023 ACL)

* Chinese Academy of Sciences
* [https://aclanthology.org/2023.acl-long.411/](https://aclanthology.org/2023.acl-long.411/)
* 对 NL2Code 的 27 个现有大型语言模型进行了全面调查，并回顾了基准和指标。在 HumanEval 基准上对所有现有模型进行直观比较。通过深入观察和分析，得出一些见解并得出结论：NL2Code 大型语言模型成功的关键因素是“大尺寸、优质数据、专家调优”。

### A Survey on Model Compression and Acceleration for Pretrained Language Models (2023 AAAI)

* University of California
* [https://ojs.aaai.org/index.php/AAAI/article/view/26255](https://ojs.aaai.org/index.php/AAAI/article/view/26255)
* 重点关注推理阶段，回顾预训练语言模型的模型压缩和加速的当前状态，包括基准、指标和方法。

### A Survey on Evaluation of Large Language Models

* Jilin University
* [https://arxiv.org/pdf/2307.03109.pdf](https://arxiv.org/pdf/2307.03109.pdf)
* 对大模型的这些评估方法进行了全面的回顾，重点关注三个关键维度：评估什么、评估在哪里以及如何评估。

### A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT

* Michigan State University
* [https://arxiv.org/pdf/2302.09419.pdf](https://arxiv.org/pdf/2302.09419.pdf)
* 面回顾了 PFM (Pretrained Foundation Models) 在文本、图像、图表以及其他数据模式方面的最新研究进展、挑战和机遇。该综述涵盖了自然语言处理、计算机视觉和图形学习中使用的基本组件和现有预训练方法。此外，它还探索了用于不同数据模式的高级 PFM 以及考虑数据质量和数量的统一 PFM。该评论还讨论了与 PFM 基础相关的研究，例如模型效率和压缩、安全性和隐私。

### ChatGPT is not all you need. A State of the Art Review of large Generative AI models

* [https://arxiv.org/pdf/2301.04655.pdf](https://arxiv.org/pdf/2301.04655.pdf)
* Universidad Pontificia Comillas
