---
sort: 2
---


# 工程实践

* [算法开发手册](https://kg-nlp.github.io/Algorithm-Project-Manual/表格解析/工程实践.html)

* [个人知乎](https://www.zhihu.com/people/zhangyj-n)


## 算法

* IGSQL
    * 基于paddle[上下文相关的 Text2SQL 任务](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/text_to_sql/IGSQL)
* Enhanced RAT-SQL
    * 基于paddle[Text2SQL 任务](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/text_to_sql/RAT-SQL)


## 预训练模型

### [SPACE-T表格问答中文大规模预训练模型介绍](https://modelscope.cn/models/damo/nlp_convai_text2sql_pretrain_cn/summary)
*  官方示例
    *  中文表格问答（TableQA）模型是一个多轮表格知识预训练语言模型，可用于解决下游的多轮Text-to-SQL语义解析任务。该模型并通过海量中文表格数据预训练(千万级)，在中文Text2SQL数据集上取得不错的效果。本模型是SPACE系列模型的一员，SPACE-T（SPACE-Table的简称）
    *  任务简要描述：给定表格（例如基金信息表）的情况下，用户输入基于表格的自然语言问题（例如，XX公司的基金有哪些风险类型？），模型会将用户的自然语言问题转化成SQL查询语句（例如，SELECT 风险类型 FROM 基金信息表 WHERE 公司名称 = XX），并且在该表格对应的数据库中执行该SQL语句，从而返回查询结果（例如，“低风险”、“中高风险”）；（详细示例见代码范例）
    *  模型结构上，采用统一的 Transformer 架构作为模型底座，对输入的自然语言问题和表格的schema结构进行理解。然后，采用sketch-based方法分别预测SQL语句中select子句和where子句，从而构成最终的SQL语句。模型结构如下图: ![SPACE-T模型结构](https://modelscope.cn/api/v1/models/damo/nlp_convai_text2sql_pretrain_cn/repo?Revision=master&FilePath=resources/star.jpg&View=true)
    *  基础表格能力

    | 能力 | 解释 | 示例问题 | 示例SQL |
    | --- | --- | --- | --- | 
    | 多列查询 | SELECT子句中支持选择多个不同的column|列出油耗大于8但是功率低于200的**名称和价格** |SELECT **产品名称, 零售价** FROM 汽车 WHERE ( 综合耗油量 > "8" ) AND ( 功率 < "200")|
    | 聚合函数查询 | SELECT子句支持选择不同的聚合函数，包括：COUNT、SUM、AVG | 上个月收益超过3的**有几个**基金？ | SELECT **COUNT(基金名称)** FROM 基金 WHERE ( 月收益率 > "3" ) |
    | | | 长江流域和珠江流域的水库**库容总量**是多少？ | SELECT **SUM(库容)** FROM 水库 WHERE ( 所在流域 == "长江" ) OR ( 所在流域 == "珠江" ) |
    | 值比较条件 | WHERE子句支持等于、大于、小于、不等于运算符 | **计算机**或者**成绩优秀**的同学有哪些？学号是多少？ | SELECT 学号, 学位 FROM 学生信息 WHERE ( **专业名称 == "计算机"** ) OR ( **成绩 == "优秀"** ) |
    | | | 列出**油耗大于8**但是**功率低于200**的名称和价格 | SELECT 产品名称, 零售价 FROM 汽车 WHERE ( **综合耗油量 > "8"** ) AND ( **功率 < "200"** ) |
    | | | **净值不等于1**的基金平均月收益率和年收益率是多少？ | SELECT AVG(月收益率), AVG(今年年收益率) FROM 基金 WHERE ( **净值 != "1"** ) |
    | 多条件并存 | WHERE子句支持多个条件以AND或OR的形式组合查询 | 长江流域**和**珠江流域的水库库容总量是多少？ | SELECT SUM(库容) FROM 水库 WHERE ( 所在流域 == "长江" ) **OR** ( 所在流域 == "珠江" ) |
    | | | 列出油耗大于8**但是**功率低于200的名称和价格 | SELECT 产品名称, 零售价 FROM 汽车 WHERE ( 综合耗油量 > "8" ) **AND** ( 功率 < "200" ) |
    | 自动补充列名 | 查询列名=值的情况下，用户可以省略列名 | **计算机**或者成绩优秀的同学有哪些？学号是多少？ | SELECT 学号, 学位 FROM 学生信息 WHERE ( **专业名称 == "计算机"** ) OR ( 成绩 == "优秀" ) |
    | | | 油耗低于5的**suv**有哪些？ | SELECT 产品名称 FROM 汽车 WHERE ( **汽车类型 == "suv"** ) AND ( 综合耗油量 < "5" ) |
    | 一定的泛化能力 | 对于列名的询问不要求完全匹配表格中的列名 | **油耗**低于5的suv有哪些？ | SELECT 产品名称 FROM 汽车 WHERE ( 汽车类型 == "suv" ) AND ( **综合耗油量** < "5" ) |
    | | | **上个月收益**超过3的有几个基金？ | SELECT COUNT(基金名称) FROM 基金 WHERE ( **月收益率** > "3" ) |
    | 拒识能力 | 拒绝和表格无关的询问 | 今天星期几？ | SELECT 空列 |
    | | | 冬至吃不吃饺子？ | SELECT 空列 |
    | 多轮对话能力（SDK中可使用，在线体验DEMO中无法使用） | 记录历史信息并进行多轮对话 | 1. 珠江流域的小型水库的库容总量是多少 </br> 2. 那平均值是多少？ </br> 3. 换成中型的呢？ | 1. SELECT SUM(库容) FROM 水库 WHERE ( 工程规模 == "小型" ) AND ( 所在流域 == "珠江" )  </br>  2. SELECT AVG(库容) FROM 水库 WHERE ( 工程规模 == "小型" ) AND ( 所在流域 == "珠江" ) </br> 3. SELECT AVG(库容) FROM 水库 WHERE ( 工程规模 == "中型" ) AND ( 所在流域 == "珠江" ) |

    * 组合能力表格
    
    | 能力 | 示例问题 | 示例SQL |
    | ---------- | ---------- | ---------- |
    | 多列查询 + 多条件并存 + 自动补充列名 | 计算机或者成绩优秀的同学有哪些？学号是多少？ | SELECT 学号, 学位 FROM 学生信息 WHERE ( 专业名称 == "计算机" ) OR ( 成绩 == "优秀" ) |
    | 多条件并存 + 值比较条件 + 自动补充列名 + 泛化能力 | 油耗低于5的suv有哪些？ | SELECT 产品名称 FROM 汽车 WHERE ( 汽车类型 == "suv" ) AND ( 综合耗油量 < "5" ) |
    | 聚合函数查询 + 值比较条件 + 泛化能力 | 上个月收益超过3的有几个基金？ | SELECT COUNT(基金名称) FROM 基金 WHERE ( 月收益率 > "3" ) |
    
    * 使用demo
    
    ```python
    import os, json
    from transformers import BertTokenizer
    from modelscope.models import Model
    from modelscope.outputs import OutputKeys
    from modelscope.pipelines import pipeline
    from modelscope.preprocessors import TableQuestionAnsweringPreprocessor
    from modelscope.preprocessors.nlp.space_T_cn.fields.database import Database
    from modelscope.utils.constant import ModelFile, Tasks
    
    model_id = 'damo/nlp_convai_text2sql_pretrain_cn'
    test_case = {
        'utterance':
        [['长江流域的小型水库的库容总量是多少？', 'reservoir'], ['那平均值是多少？', 'reservoir'], ['那水库的名称呢？', 'reservoir'], ['换成中型的呢？', 'reservoir']]
    }
    
    model = Model.from_pretrained(model_id)
    tokenizer = BertTokenizer(
        os.path.join(model.model_dir, ModelFile.VOCAB_FILE))
    db = Database(
        tokenizer=tokenizer,
        table_file_path=os.path.join(model.model_dir, 'table.json'),
        syn_dict_file_path=os.path.join(model.model_dir, 'synonym.txt'),
        is_use_sqlite=True)
    preprocessor = TableQuestionAnsweringPreprocessor(
        model_dir=model.model_dir, db=db)
    pipelines = [
        pipeline(
            Tasks.table_question_answering,
            model=model,
            preprocessor=preprocessor,
            db=db)
    ]
    
    for pipeline in pipelines:
        historical_queries = None
        for question, table_id in test_case['utterance']:
            output_dict = pipeline({
                'question': question,
                'table_id': table_id,
                'history_sql': historical_queries
            })[OutputKeys.OUTPUT]
            print('question', question)
            print('sql text:', output_dict[OutputKeys.SQL_STRING])
            print('sql query:', output_dict[OutputKeys.SQL_QUERY])
            print()
            historical_queries = output_dict[OutputKeys.HISTORY]
    ```
    * 微调demo
    
    ```python
    import os, json
    from modelscope.msdatasets import MsDataset
    from modelscope.trainers.nlp.table_question_answering_trainer import TableQuestionAnsweringTrainer
    from modelscope.utils.constant import DownloadMode
    
    input_dataset = MsDataset.load(
        'ChineseText2SQL', download_mode=DownloadMode.FORCE_REDOWNLOAD)
    train_dataset = []
    for name in input_dataset['train']._hf_ds.data[1]:
        train_dataset.append(json.load(open(str(name), 'r')))
    eval_dataset = []
    for name in input_dataset['test']._hf_ds.data[1]:
        eval_dataset.append(json.load(open(str(name), 'r')))
    print('size of training set', len(train_dataset))
    print('size of evaluation set', len(eval_dataset))
    
    model_id = 'damo/nlp_convai_text2sql_pretrain_cn'
    trainer = TableQuestionAnsweringTrainer(
        model=model_id,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
    )
    trainer.train(
        batch_size=8,
        total_epoches=2,
    )
    trainer.evaluate(
        checkpoint_path=os.path.join(trainer.model.model_dir, 'finetuned_model.bin'))
    ```
## 开源工程问题

* [ChatSQL开源项目](https://github.com/cubenlp/ChatSQL)  (已经试过效果不好,但流程还是要学习一下)
    *  了解数据库表的格式处理,向量化表示
    *  不要相信ChatGLM的数学计算能力和NL2SQL能力
* [DB-GPT: 用私有化LLM技术定义数据库下一代交互方式](https://github.com/eosphoros-ai/DB-GPT/blob/main/README.zh.md)

## DB-GPT
* DB-GPT 是什么？
 
> 随着大模型的发布迭代，大模型变得越来越智能，在使用大模型的过程当中，遇到极大的数据安全与隐私挑战。在利用大模型能力的过程中我们的私密数据跟环境需要掌握自己的手里，完全可控，避免任何的数据隐私泄露以及安全风险。基于此，我们发起了DB-GPT项目，为所有以数据库为基础的场景，构建一套完整的私有大模型解决方案。 此方案因为支持本地部署，所以不仅仅可以应用于独立私有环境，而且还可以根据业务模块独立部署隔离，让大模型的能力绝对私有、安全、可控。我们的愿景是让围绕数据库构建大模型应用更简单，更方便。

* 目前能力
    * SQL 语言能力
        * SQL生成
        * SQL诊断
    * 私域问答与数据处理
        * 知识库管理(目前支持 txt, pdf, md, html, doc, ppt, and url)
        * 数据库知识问答
        * 数据处理
    * 数据库对话
    * Chat2Dashboard
    * 插件模型
        * 支持自定义插件执行任务，原生支持Auto-GPT插件。如:
            * SQL自动执行，获取查询结果
            * 自动爬取学习知识
    * 知识库统一向量存储/索引
        * 非结构化数据支持包括PDF、MarkDown、CSV、WebURL
    * 多模型支持
        *  支持多种大语言模型, 当前已支持如下模型:
        *  🔥 Vicuna-v1.5(7b,13b)
        *  🔥 llama-2(7b,13b,70b)
        *  WizardLM-v1.2(13b)
        *  Vicuna (7b,13b)
        *  ChatGLM-6b (int4,int8)
        *  ChatGLM2-6b (int4,int8)
        *  guanaco(7b,13b,33b)
        *  Gorilla(7b,13b)
        *  baichuan(7b,13b)
* [构建镜像环境](https://db-gpt.readthedocs.io/projects/db-gpt-docs-zh-cn/zh_CN/latest/getting_started/getting_started.html)

```bash
bash docker/build_all_images.sh \
--base-image nvidia/cuda:11.8.0-devel-ubuntu22.04 \
--pip-index-url https://pypi.tuna.tsinghua.edu.cn/simple \
--language zh
```

