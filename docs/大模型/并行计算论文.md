---
sort: 2
---

# 并行计算论文

## 张量模型并TP Megatron-LM

[知乎链接](https://zhuanlan.zhihu.com/p/622212228)

1.  基本思想

- 属于模型并行，把模型参数纵向切开放到不GPU上。
-  一台机器上有多个GPU，为跑一个大模型，不一定要用所有的卡，因为设备间的通信可能导致GPU使用率变低，使用部分卡就可以满足要求了。

2.  Nvidia TP

-   切分权重的方法，按行切分或按列切分
-   MLP
    -  以GELU为例，有两个线性层来表示参数，输入层－隐藏层－输出层；在两层之间各有一个线性层计算参数（先不考虑参数的梯度计算）
    -  先进行列切割，再进行行切割
    -   规定通讯量为 $$\Phi =b*s*h$$,MLP在forward和backward时各进行一次AllReduce,每次的通讯量时$$2\Phi$$,所以MLP层的总通讯量是$$4\Phi$$
-  Self-Attention层
    -  attention的多头计算就是为张量并行量身定做的，每个头都可以独立计算，最后将结果concat起来；对于三个参数矩阵QKV按列切割，后面的线性层按行切割；
    *   通讯量为$$4\Phi$$
-   输入输出的Embedding层
    -   当模型的输入输出层都在一块GPU上，可以方便的使用两次的梯度总和进行权重更新
    -   当在不同GPU上时，需要对word embedding的梯度做一次AllReduce
-   交叉熵层
    -   当词表v很大时，通讯开销不容忽视，需要对词表进行切分
-   张量并行+数据并行
    -   一台机器上做张量并行，不同机器间做数据并行
    -   张量并行TP的通讯量$$\Phi_{TP}=b*s*h$$,数据并行DP的通讯量$$\Phi_{DP}=h*h$$,忽略常数项，最后比较的是$$[b*s]vs[h]$$,通常大模型训练时的batchsize很大
-   实验结果
    -   随着模型增加，需要的GPU数量变多，通讯量会增大，单卡的计算效率在下降，有时候几个卡就可以代替所有卡的效果。
    -   当模型增大时，不仅是参数变多，还有例如activation这样的中间结果，也会占据大部分显存，因此需要的GPU数量渐渐不再和模型大小成正比了，如果不引入显存优化，光有很多显卡也装不了大模型。

## 数据并行DP DeepSeed ZeRO

[知乎链接](https://zhuanlan.zhihu.com/p/618865052)

1.  DDP

-   DDP通过采用Ring-AllRdeuce这一NCCL操作，使得通讯量均衡分不到每块GPU上，实现了负载均衡的优化

2.  ZeRO

-   显存开销问题，数据并行时，每个GPU上都会复制一份完整模型，当模型变大时，显存容易不够，需要使用零冗余优化，核心思想用通讯换显存
-   存储分类
    -   Model States 和 Residual States
    -   model states包括优化器的参数，模型梯度，模型参数
    -   residual states是模型非必须的，是在训练过程中额外产生的内容。像activation激活函数的值，有的话可以快速计算梯度值；temporary buffers临时存储，比如说把梯度发送到某块GPU上做聚合产生的存储；还有unusable fragment memory碎片化的存储空间，虽然总存储空间足够，但如果取的时候不是连续的存储空间，有些请求可能会失败。
    -   混合精度训练可以减少一部分存储问题

3.  ZeRO-DP

-   知道什么东西占显存，以及占多大，再说优化
-   优化器，梯度，参数分割，分到每个GPU上，减少显存开销
-   ZeRO是模型并行的形式，数据并行的实质
    -   模型并行：同样的输入X，每块GPU上各算模型的一部分，最后通过某些方式聚合结果。
    -   数据并行：不同的输入X，需要完整的参数，最后输出结果

4.  ZeRO-R

-   activation需要灵活设置，对显存的占用一般远高于模型本身，通讯量也大，可以适当的分在每块GPU上，或有取舍的保留哪些activation。
-   固定大小缓存
-   整合碎片化空间

5.  offload和infinity

-   显存不够，内存来凑
-   前向传播和反向传播计算量高，放到GPU，update计算量低，放到CPU中


## 参考
[ColossalChat](https://github.com/hpcaitech/ColossalAI/tree/main/applications/Chat)  
[1维, 2维, 2.5维, 3维 张量并行](https://arxiv.org/abs/2105.14500)  
[序列并行](https://arxiv.org/abs/2105.13120)  
[零冗余优化器 (ZeRO)](https://arxiv.org/abs/1910.02054)  
[自动并行 ](https://arxiv.org/abs/2302.02599) 
[异构内存管理](https://arxiv.org/abs/2108.05818)  

 
