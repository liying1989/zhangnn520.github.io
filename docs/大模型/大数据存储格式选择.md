---
sort: 3
---

# 大数据存储格式选择 

## 基于pandas的数据格式
* 目标：单机处理大数据时，能以较小空间存储数据，并且能快速加载进行后续处理
* 使用工具：pandas
* 文件比较
    * Excel 文件由于格式相对复杂，所以读取时间和内存消耗较大，一般在数据分析过程中只作为输入数据的一种存在
    * CSV 格式简单，通用性强，但没有压缩，且存在数据类型问题，一般用于跨软件交换数据或者少量简单数据的存储。
    * h5 文件较大，但比 CSV 小，读取速度比 CSV 快，内存占用稍高，可以作为中间结果的存储格式。
    * parquet 文件最小，读取速度比较快，内存占用一般，适合作为数据存储格式。
    
> excel 二进制存储,文件会小些,但加载占用内存高,读取时间久
> csv文件会大些,但读取快
> h5和parquet好些


* 测试  


```python  
import os
current_path = os.path.abspath(os.path.dirname(__file__))  # 设置绝度路径

# 导出
file_path = 'norm_search.csv'
df.to_excel(file_path.replace('csv','xlsx'),index=False)
f.to_csv(file_path.replace('csv','tsv'),sep='\t',index=False)
f.to_hdf(file_path.replace('csv','h5'),'data',index=False)
f.to_parquet(file_path.replace('csv','parquet')) 
  
# 加载         
start = time.time()
df = pd.read_feather('norm_search.feather')
logger.info('read_feather: '+timeSince(start))
print(df.columns.tolist())

start = time.time()
df = pd.read_hdf('norm_search.h5','data')
logger.info('read_hdf: '+timeSince(start))
print(df.columns.tolist())

start = time.time()
df = pd.read_parquet('norm_search.parquet')
logger.info('read_parquet: '+timeSince(start))
print(df.columns.tolist())

start = time.time()
df = pd.read_excel('norm_search.xlsx')
logger.info('read_excel: '+timeSince(start))
print(df.columns.tolist())

start = time.time()
df = pd.read_csv('norm_search.tsv',sep='\t')
logger.info('read_csv: '+timeSince(start))
print(df.columns.tolist())
```    


* 结果

| 格式 | 文件大小 | 读取时间 |
| --- | --- | --- |
| feature | 3.71M | 89ms |
| parquet | 4.42M | 127ms |
| tsv | 44.2M | 392ms |
| h5 | 132M | 456ms |
| xlsx | 4.50M | 9547ms |


* 注意：在导出parquet时，注意字段下的内容格式保持一致后期基本都是使用parquet文件


[参考链接](https://www.kaggle.com/code/rohanrao/tutorial-on-reading-large-datasets/notebook)
