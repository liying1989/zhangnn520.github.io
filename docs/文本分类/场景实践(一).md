# 场景实践(一)


* [算法开发手册](https://kg-nlp.github.io/Algorithm-Project-Manual/文本分类/场景实践(一).html)

* [个人知乎](https://www.zhihu.com/people/zhangyj-n)

* [分类常见问题](https://kg-nlp.github.io/Algorithm-Project-Manual/文本分类/分类常见问题.html)


## 难例分析

* 难例总结
    * 运行-用户输入数据与已有训练集数据相似度极低(基于特征级)可以作为难例(可能训练集覆盖度不够,算法评估)
    * 运行-用户输入数据阈值很低,或者阈值很高但与其他数据相似(算法评估)
    * 运行-用户输入数据新的关键词未在训练集中出现(训练集覆盖度不够)
    * 运行-能够通过规则完全确定,但模型识别不同(算法评估)(规则:特短文本直接映射标签)    --- 规则表通过业务框架和训练数据确定范围
    * 开发-基于字面相似度计算训练集中样本相似但标签不同的数据(可能是错标的数据)
    * 开发-计算训练集中预测错误的数据(算法评估)
    * 开发-训练过程(基于实例级)对loss影响大的数据(算法评估) 
* 难例使用
    * 难例挖掘
    * 难例校核
    * 难例补充训练集
    * 重新训练
    * 运行期的方法都可在开发期使用
* 难例区分
    * 针对模型,只要没有识别正确就是难例(范围大)
    * 针对人员,不能够区分的就是难例(过滤,校核)

* 代码总结

```

```

## 

## 问题解决

> Q1: 如何科学地构建分类标签体系？   
> Q2: 标注是「人工」智能的精髓所在，如何省成本、鲁棒、高效地构建任务数据集？  
> Q3: 模型化就是唯一吗？分类任务中，算法策略构建的基本原则是什么？     
> Q4: 特征挖掘立竿见影，如何在特征工程方面搞点事情？       
> Q5: 数据为王，不要将数据闲置，如何将无标注数据更好地派上用场？    
> Q6: 攻克分类任务的难点：如何更好处理不平衡问题（hard example问题）？    
> Q7: BERT时代，如何处理长文本分类？        
> Q8: 预训练融合：NLP竞赛利器！          
> Q9: 你认真构造离线测试集了吗？指标高，也许是虚高！     
> Q10: 模型更新迭代时，如何进行增量学习，不遗忘先前记忆？  
> Q11: 低耗时场景，如何让TextCNN逼近BERT的效果？            

![分类流程](https://note.youdao.com/yws/api/personal/file/WEB92ef0941ce1774c5ba62b8dd41404027?method=download&shareKey=e45926fef2fdaa14262459a33494ad5a)

* **Q1: 如何科学地构建分类标签体系？**
    * **长尾标签**: 将业务含义不清,或表达无效的数据标注为"其他",目前没有对"其他"标签进行后续分类识别
    * **易混淆标签**:将确定的多标签都标注出,不确定的标注为"其他",但对于几个特殊的业务标签,即时不确定目前也都标注出所有可能性,这是为了统一标注规则防止不同标注人员标注训练集和测试集时标注意识不同(这种方式需要约定)
    * **多标签**: 现在有三个层级的多标签,除了第一个层级5个类别外,其他两个在30-40左右,层级间依次包含;一开始分成三个模型识别;之后分成两个模型;多个二分类的场景没有去做,虽然可以标签分类相对独立,但资源消耗太多(目前使用预训练模型,测试过RNN或CNN类模型准确率会低几个点,并且每个小模型几十M,数量多占用资源也多)
    * **未知标签**:现在标注为"其他"; 虽然通过文本聚类可以粗略分组,但数据长度较短,业务含义难懂,聚类完由业务人员再分析也没有减少多少工作量
    
* **Q2: 标注是「人工」智能的精髓所在，如何省成本、鲁棒、高效地构建任务数据集？**
    *  **构建初始数据集**: 初步构造时由算法人员从数据库中拉取数据,经过过滤,去重筛选出几千条(正常应该一个标签对应200条,但因为标签类别有30个,标注难度大,有个别标签对应的数据很少,最终也没有按照最初要求来做,所以开始只标注了2000条,而且标签比例不均衡,标注很耗时2000条得3/4天)
    *  **「主动学习+迁移学习」降低标注规模**：
        *   **主动学习旨在挖掘高价值样本**: 对于熵最大+代表性高的数据没有业务专家介入的话,我们很难确定哪些数据最具代表性,算法人员能做的就是尽量从众多的数据中筛选出不相似的,非重复的数据;前期更多利用统计思想快速提取,可以参考之前总结的方法[数据去重筛选](https://kg-nlp.github.io/Algorithm-Project-Manual/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E6%95%B0%E6%8D%AE%E5%8E%BB%E9%87%8D%E7%AD%9B%E9%80%89.html);当然除了这些,还有根据业务场景指定关键词或业务字段筛选数据。
        *   **迁移学习降低对数据的依赖**： 首先深度学习发展到现在这个阶段，首选自然而然是用预训练模型微调，但我们现在做的业务场景比较难，数据分布其实和原预训练模型还是有很大差别的，所以标注数据还是越多越好，目前30000+数据,30个类别(数据不均衡)效果还算可以,acc接近95%[LLM综述](https://kg-nlp.github.io/Algorithm-Project-Manual/%E5%A4%A7%E6%A8%A1%E5%9E%8B/LLM%E7%BB%BC%E8%BF%B0.html)
        *   **扩充标注规模，数据增强最为关键**:扩充数据有以下几个方面
            * [数据增强](https://kg-nlp.github.io/Algorithm-Project-Manual/数据分析/数据增强.html)   
            * 利用业务框架生成标注数据
            * 利用业务词库替换EDA模型默认词库
            * 增加标志位区分不同来源数据:"标志1","标志2"
        * **清洗数据噪音，让模型更加鲁棒**: 重中之重,花费了大量的时间在标注数据清洗上
            * 由于前期没有规范的标注流程以及业务本身的难度之大,实习生标注后的数据存在很多问题,与最终业务人员给的测试集出入很大,导致模型结果很差,所以后期花费了大量时间在校核数据上.
            * **人工规则清洗**:光有关键词没有用,需要结合业务框架识别标注的准不准确,有些拿不准的还得积攒一轮和业务专家一起校核
            * **交叉验证**: 如果使用的是轻量级模型,最好使用交叉验证寻找标签不一致的数据,但我们此次使用的是预训练模型,并且一次找出大量的错误数据让业务专家校核不现实(业务专家没办法拿出几天时间集中去校核),只能通过寻找难例的方法迭代测试,一轮一轮的和业务专家一起校核,1-2个小时就能搞定。经过很多轮的校核后，作为算法人员对数据的业务含义理解的也更深入了，后期一些简单问题也能独立解决。
            * **置信学习**：对交叉验证的进一步推广，寻找置信度比较低的数据
            * **深度KNN过滤**：==这个还没有试过，可以看下论文尝试==
            * 针对少样本问题，可以使用规则（样本少好总结）解决
            * 智能标注本质是高效的，但实际上还是由业务专家去校核，一条一条的过，具体有没有提效真不好说
            * 预训练模型要具备领域性，不要停止预训练！这个我们也正在使用领域数据进行增量训练[垂直领域小模型快速训练（一）](https://kg-nlp.github.io/Algorithm-Project-Manual/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E5%B0%8F%E6%A8%A1%E5%9E%8B%E5%BF%AB%E9%80%9F%E8%AE%AD%E7%BB%83%EF%BC%88%E4%B8%80%EF%BC%89.html)
* **Q3: 模型化就是唯一吗？分类任务中，算法策略构建的基本原则是什么?**
    * 算法策略主要包括规则挖掘和模型化方法
    * **规则兜底**: 对于高频case,hard case优先进入规则模型(这个目前没有做,全靠模型输出)
    * **模型泛化**: 尽可能提升效果使用模型结果

* **Q4: 特征挖掘立竿见影，如何在特征工程方面搞点事情？**
    * 这块的内容还没有很好的复现

* **Q5: 数据为王，不要将数据闲置，如何将无标注数据更好地派上用场？**
    * 自监督学习: 继续预训练
    * UDA(这个可以尝试做一下)

* **Q6: 攻克分类任务的难点：如何更好处理不平衡问题（hard example问题）？**
    *  重采样（re-sampling）和重加权（re-weighting）
    *  欠采样和过采样都不合适
    *  loss类别加权,focal loss,ghm loss, dice loss 都不好使,不均衡的比例太大了
    

* **Q7: BERT时代，如何处理长文本分类？**
    * 这里长文本很少,直接128截断
    
* **Q8: 预训练融合：NLP竞赛利器！**
    * 再加一层全连接,或者多几个特征提取,融合在一起试试(还没有做)
    
* **Q10: 模型更新迭代时，如何进行增量学习，不遗忘先前记忆？**
    * 直接现有数据与原有数据混合训练(现在一直这么高,数据最多的时候50000+,训练时间可以接受)
    * 将特征抽取层freeze，对新类别只更新softMax全连接层；(这个和上面说的差不多,只是需要把预训练模型只当做个特征提取工具)
    * 采取知识蒸馏方式。在现有数据与原有数据混合一起训练时，对原有类别进行蒸馏，指导新模型学习.(这个不错,可以蒸馏试试)
    * 将分类任务转为检索任务,匹配样本和标签的embedding(这个做过,效果只比分类任务差几个点)
    
* **Q11: 低耗时场景，如何让TextCNN逼近BERT的效果？**
    * 本身paddle的基座模型有蒸馏的小模型,但效果不好 
    * 也可以大模型学习后,再进行模型蒸馏,但准确率不能保证
    * 数据蒸馏对应我们的业务场景不适用,虽然有大量无标注的数据,但很难标注啊,在当前标注数据上做了些数据增强,替换同义词+相同语义生成,结果也没有太大提升,我怀疑标注的数据还是有问题的,再怎么增强也无济于事


## 参考
* [如何解决NLP分类任务的11个关键问题：类别不平衡&低耗时计算&小样本&鲁棒性&测试检验&长文本分类](https://zhuanlan.zhihu.com/p/183852900)
